Process Creation: system initialization, execution of process creation using system call by running a process, user request to create new process and initiation of a batch job. Process states: running - using the cpu, ready - runnable but is temporarily stopped by the running process, Blocked - cannot run until external event is happening.CPU utilization = 1 -p^n. P is fraction of waiting, n is number of processors. The biggest advantage is the efficiency. No traps to the kernel are needed to switch threads. The biggest disadvantage is that if one thread blocks, the entire process blocks. If a single-threaded process is blocked on the keyboard, it cannot fork.Race condition: two process race to get a certain resource, only one gets it, while the other thinks it has it.Critical regions: memory areas sensitive to race conditions.Mutual Exclusion with Busy Waiting: attempt to solve CR issue, only work with single core processes, and only good for kernel.Lock variable solution alone still has race condition. strict alternation: could violates rule 3, and only works for 2 process. Peterson solution: uses lock and strict,but keeps track of interested processes.Semaphore: using an integer to count number of wake up for later. It is atomic - cannot be interrupted, while calling it. Only one can access it at a time. Futex - fast user space mutex - used in linux as to avoid tapping to the kernel as much as possible.Monitors: A high level synchronization primitive. A collection of procedures, variables, and data structures that are all grouped together in a special kind of module or package. Scheduling Algorithm Goals: All System;Fairness - giving each process a fair share of the CPU,Policy Enforcement - seeing that stated policy is carried out, Balance - keeping all parts of system busy, Batch Systems:Throughput - maximize jobs per hour, Turnaround time - minimize time between submission and termination, CPU Utilization - keep the CPU busy all the time. Interactive Systems: Response time - respond to requests quickly, Proportionality - meet users' expectations. Real-time systems: Meeting deadlines - avoid losing data Predictability - avoid quality degradation in multimedia systems. Conditions for Resource Deadlocks: Mutual Exclusion:Each resource is either currently assigned to exactly one process or is available. Hold-and-Wait:Processes currently holding resources that were granted earlier can request new resources.No-preemption: Resources previously granted cannot be forcibly taken away from a process. They must be explicitly released by the process holding them.Circular wait condition:There must be a circular list of two or more processes, each of which is waiting for a resource held by the next member of the chain. Actual ways to solve deadlocks: Deadlock Detection and Recovery - builds a graph, looks for cycles. Deadlock Detection w/ Multiple Resources of Each Type:, uses matrix, where a column is the type of class, row represents a process, looks for less than or equal to the Available matrix. To recover of deadlock: use Preemption, use rollback, killing process. Deadlock Avoidance: Resource Trajectories, Safe and Unsafe states. Deadlock Prevention: Attacking Mutual-Exclusion Condition:  data - Can simply make read-only, that way all processes can access. Attacking the Hold-and-Wait Condition: prevent processes that hold requests from waiting for more resources, we can eliminate deadlocks. Require all processes to request all their resources before starting execution. Attacking No-preemption Condition: Some resources can be virtualized. Attacking Circular Wait Condition: example: Have a rule saying that a process is entitled only to a single resource at any moment; If it needs a second one, it must release the first one. Livelock:  they lock, they try to free resources, they ask again, they lock again, for ever. Starvation: a process does not get blocked, but never gets to run, due to some condition - it starves.No Memory Abstraction: Early computers had no memory hierarchy, and stored everything in physical memory, To get parallelism (in related programs) is to program with multiple threads. Running Multiple Programs without Memory Abstraction OS has to save the entire contents of memory to disk file, then bring in and run the next program. As long as there is only one program at a time in memory, there will be no conflicts. A Memory Abstraction: Address Spaces - used to solve two issues - protection and relocation:. Address space is similar in the concept of abstract cpu to run programs. Address space has its own set of addresses that a process can use to address memory. Each process has its own address space. Base and Limit Registers - simple version of dynamic relocation. Base is loaded with physical address where program begins, limit has the length of the program. Every time a process references memory, either to fetch an instruction or read or write a data word, the CPU hardware automatically adds the base value to the address generated by the process before sending the address out on the memory bus. Swapping: Bringing each process in its entirety, running it for a while, the putting it back on the disk. Managing Free Memory: Memory Management with Bitmaps: memory is divided to allocation units, each allocation is being mapped in a bitmap, a small bit can have more precision, but make the map larger, a larger unit, makes map smaller but can allocate extra memory for no reason. The issue with this, is that searching a map is a slow process. Mem management with linked list - free memory segments, each segment may have a process or is empty, each segment specifies a hole(H), or a process(P), an address where it starts, length and pointer to next segment. Page Replacement Algorithms: The Optimal Page Replacement Algorithm: the idea to fetch the pages that we know we need for the next immediate set of instruction. It is not possible because a program cannot predict the future.NRU algorithm: removes a page at random from the lowest-numbered nonempty class.It is better to remove a modified page that has not been referenced in at least one clock cycle, than a clean page in heavy use.FIFO Replacement: . On page fault, page at head(oldest) is removed, and new page added to tail of list(newst), Not useful, since oldest page might still be really useful. Second-Chance Page Replacement: Second chance at FIFO is to inspect the R bit of the oldest page, if 1 then it is being treated as a new page. Clock Page Replacement: Instead of moving pages around in Second-Chance, have all the page frames in a circular list (form of a clock), if page fault, but R bit is 1, continue to the next one - like an intergiation. Least Recently Used (LRU) Replacement(hardware, NFU is software):  trivial, remove pages that has not been used for a while, and likely not be used in the near future. The Working Set Page Replacement Demand Paging - Pages are loaded on demand, as needed. As opposed to pre-loading in advance, Locality of reference - during any phase of execution, the process references only a relatively small fraction of its pages, Working set - set of pages that a process is currently using. SOME INFORMATION WAS QUOTED FROM THE BOOK